{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 4 - CHALLENGED AMADEUS: Match searches with bookings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Guide:\n",
    "    * For every search in the searches file, find out whether the search ended up in a booking or not (using the info in the bookings file). For instance, search and booking origin and destination should match. \n",
    "    * For the bookings file, origin and destination are the columns dep_port and arr_port, respectively. \n",
    "    * Generate a CSV file with the search data, and an additional field, containing 1 if the search ended up in a booking, and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, importamos la librería \"Pandas\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos viendo cuantos registros no duplicados hay en el fichero \"searches\" y generando un fichero csv con todos estos registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 358999\n",
      "1 359003\n",
      "2 359003\n",
      "3 359003\n",
      "4 359003\n",
      "5 359003\n",
      "6 359003\n",
      "7 359003\n",
      "8 359003\n",
      "9 359003\n",
      "10 359003\n",
      "11 359003\n",
      "12 359003\n",
      "13 359003\n",
      "14 359003\n",
      "15 359003\n",
      "16 359003\n",
      "17 359003\n",
      "18 359003\n",
      "19 359003\n",
      "20 359004\n"
     ]
    }
   ],
   "source": [
    "#Leemos el fichero fijando el número de filas que importaremos al DF en cada iteración con el tamaño de los Chunks.\n",
    "#Además, indicamos en la lectura que no prediga de que tipo es cada elemento, y que fuerce que todos los elementos sean tipo string.\n",
    "size_sm = 1000000\n",
    "s_find = pd.read_csv('./searches.csv.bz2', sep = \"^\", \n",
    "                     dtype = str, low_memory=False, chunksize = size_sm)\n",
    "#Creamos un DF vacío donde vamos a ir añadiendo los resultados de los Chunks\n",
    "sf_chunks = pd.DataFrame()\n",
    "\n",
    "#Para cada iteración de tamaño definido en el 'chunksize', se añadirán los registros duplicados a un DF vacío y nos dirá\n",
    "#cuantos no duplicados hay en cada iteración.\n",
    "for i, s in enumerate(s_find):\n",
    "    sf_chunks = sf_chunks.append(s)\n",
    "    sf_chunks.drop_duplicates(inplace=True)\n",
    "    print (i, len(sf_chunks)) \n",
    "\n",
    "#Generamos un fichero csv con los registros no duplicados sin imprimir los índices\n",
    "sf_chunks.to_csv('./searches.no_dup.csv', sep = \"^\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos lo mismo para el fichero \"bookings\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000000\n",
      "1 1000000\n",
      "2 1000000\n",
      "3 1000000\n",
      "4 1000000\n",
      "5 1000003\n",
      "6 1000003\n",
      "7 1000003\n",
      "8 1000003\n",
      "9 1000003\n",
      "10 1000003\n"
     ]
    }
   ],
   "source": [
    "#Leemos el fichero fijando el número de filas que importaremos al DF en cada iteración con el tamaño de los Chunks.\n",
    "#Además, indicamos en la lectura que no prediga de que tipo es cada elemento, y que fuerce que todos los elementos sean tipo string.\n",
    "size_sm = 1000000\n",
    "b_find = pd.read_csv('./bookings.csv.bz2', sep = \"^\", \n",
    "                     dtype = str, low_memory=False, chunksize = size_sm)\n",
    "#Creamos un DF vacío donde vamos a ir añadiendo los resultados de los Chunks\n",
    "bf_chunks = pd.DataFrame()\n",
    "\n",
    "#Para cada iteración de tamaño definido en el 'chunksize', se añadirán los registros duplicados a un DF vacío y nos dirá\n",
    "#cuantos no duplicados hay en cada iteración.\n",
    "for i, b in enumerate(b_find):\n",
    "    bf_chunks = bf_chunks.append(b)\n",
    "    bf_chunks.drop_duplicates(inplace=True)\n",
    "    print (i, len(bf_chunks)) \n",
    "\n",
    "#Generamos un fichero csv con los registros no duplicados sin imprimir los índices\n",
    "bf_chunks.to_csv('./bookings.no_dup.csv', sep = \"^\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras generar los ficheros con los no duplicados, comenzamos con el plan de acción:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Seleccionamos las columnas de interés del fichero \"bookings\" para reducir el DF a lo que necesitamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el fichero de registros no duplicados y mostramos los nombres de las columnas para ver con claridad que columnas hay y como vienen sus nombres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['act_date           ', 'source', 'pos_ctry', 'pos_iata', 'pos_oid  ',\n",
       "       'rloc          ', 'cre_date           ', 'duration', 'distance',\n",
       "       'dep_port', 'dep_city', 'dep_ctry', 'arr_port', 'arr_city', 'arr_ctry',\n",
       "       'lst_port', 'lst_city', 'lst_ctry', 'brd_port', 'brd_city', 'brd_ctry',\n",
       "       'off_port', 'off_city', 'off_ctry', 'mkt_port', 'mkt_city', 'mkt_ctry',\n",
       "       'intl', 'route          ', 'carrier', 'bkg_class', 'cab_class',\n",
       "       'brd_time           ', 'off_time           ', 'pax', 'year', 'month',\n",
       "       'oid      '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.read_csv('./bookings.no_dup.csv', sep=\"^\", low_memory=False)\n",
    "b.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos saber la fecha en la que se hizo la reserva para poder matchearla con la fecha de la búsqueda, seleccionamos como columnas de interés: origen del vuelo, destino del vuelo y fecha de la reserva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('bookings.no_dup.csv', sep=\"^\", \n",
    "              usecols=['dep_port', 'arr_port', 'cre_date           '], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Quitamos los espacios en blanco de los elementos del DF del fichero de reservas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.columns=b.columns.str.strip()\n",
    "b.dep_port=b.dep_port.str.strip()\n",
    "b.arr_port=b.arr_port.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Vemos en que formatos están las fechas de ambos ficheros y nivelamos sus formatos a \"str\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos leer el fichero \"searches\" sin seleccionar las columnas interesantes ya que queremos sacar toda la información de las búsquedas que han terminado en reservas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_csv('searches.no_dup.csv', sep=\"^\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-01-01'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fecha de la búsqueda del vuelo\n",
    "s.Date[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-03-20'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fecha de la reserva del vuelo\n",
    "b.cre_date[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las fechas tienen distintos formatos, por lo que a la fecha de reserva del vuelo 'cre_date' le cambio el formato a 'str':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-03-20'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.cre_date = b.cre_date.str[:10]\n",
    "b.cre_date[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Creamos una columna con 1's al fichero de reservas, para que al hacer el merge de \"bookings\" con \"searches\" los registros con reserva contengan un 1 en esta columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['flight bookings'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cre_date</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>arr_port</th>\n",
       "      <th>flight bookings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>LHR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>SAL</td>\n",
       "      <td>CLT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>SAL</td>\n",
       "      <td>CLT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>AKL</td>\n",
       "      <td>SVO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>AKL</td>\n",
       "      <td>SVO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cre_date  dep_port  arr_port  flight bookings\n",
       "0  2013-02-22  ZRH       LHR                     1\n",
       "1  2013-03-26  SAL       CLT                     1\n",
       "2  2013-03-26  SAL       CLT                     1\n",
       "3  2013-03-26  AKL       SVO                     1\n",
       "4  2013-03-26  AKL       SVO                     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Hacemos un merge para obtener todas las búsquedas que han terminado en reserva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_b = s.merge(b,\n",
    "           how ='left',\n",
    "           left_on = ['Date', 'Origin', 'Destination'],\n",
    "           right_on = ['cre_date', 'dep_port', 'arr_port'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que hemos añadido en el merge del fichero \"bookings\", ya que una vez hecho ya no son útiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_b.drop(['cre_date', 'dep_port', 'arr_port'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Asignamos a las búsquedas que no han terminado en reserva y que por tanto tienen el valor 'NaN' en la columna 'flight bookings', el valor '0':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TxnCode</th>\n",
       "      <th>OfficeID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>NbSegments</th>\n",
       "      <th>Seg1Departure</th>\n",
       "      <th>...</th>\n",
       "      <th>Seg6Date</th>\n",
       "      <th>Seg6Carrier</th>\n",
       "      <th>Seg6BookingCode</th>\n",
       "      <th>From</th>\n",
       "      <th>IsPublishedForNeg</th>\n",
       "      <th>IsFromInternet</th>\n",
       "      <th>IsFromVista</th>\n",
       "      <th>TerminalID</th>\n",
       "      <th>InternetOffice</th>\n",
       "      <th>flight bookings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>20:25:57</td>\n",
       "      <td>MPT</td>\n",
       "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
       "      <td>DE</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TXL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>FRA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10:15:33</td>\n",
       "      <td>MPT</td>\n",
       "      <td>b0af35b31588dc4ab06d5cf2986e8e02</td>\n",
       "      <td>MD</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ATH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>KIV</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>18:04:49</td>\n",
       "      <td>MPT</td>\n",
       "      <td>3561a60621de06ab1badc8ca55699ef3</td>\n",
       "      <td>US</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ICT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>NYC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:42:40</td>\n",
       "      <td>FXP</td>\n",
       "      <td>1864e5e8013d9414150e91d26b6a558b</td>\n",
       "      <td>SE</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>STO</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:48:29</td>\n",
       "      <td>MPT</td>\n",
       "      <td>1ec336348f44207d2e0027dc3a68c118</td>\n",
       "      <td>NO</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OSL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>OSL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time TxnCode                          OfficeID Country  \\\n",
       "0  2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327      DE   \n",
       "1  2013-01-01  10:15:33     MPT  b0af35b31588dc4ab06d5cf2986e8e02      MD   \n",
       "2  2013-01-01  18:04:49     MPT  3561a60621de06ab1badc8ca55699ef3      US   \n",
       "3  2013-01-01  17:42:40     FXP  1864e5e8013d9414150e91d26b6a558b      SE   \n",
       "4  2013-01-01  17:48:29     MPT  1ec336348f44207d2e0027dc3a68c118      NO   \n",
       "\n",
       "  Origin Destination  RoundTrip  NbSegments Seg1Departure  ... Seg6Date  \\\n",
       "0    TXL         AUH        1.0         2.0           TXL  ...      NaN   \n",
       "1    ATH         MIL        0.0         1.0           ATH  ...      NaN   \n",
       "2    ICT         SFO        1.0         2.0           ICT  ...      NaN   \n",
       "3    RNB         ARN        0.0         1.0           RNB  ...      NaN   \n",
       "4    OSL         MAD        1.0         2.0           OSL  ...      NaN   \n",
       "\n",
       "  Seg6Carrier Seg6BookingCode    From IsPublishedForNeg IsFromInternet  \\\n",
       "0         NaN             NaN  1ASIWS                 0              0   \n",
       "1         NaN             NaN  1ASIWS                 0              0   \n",
       "2         NaN             NaN  1ASIWS                 0              0   \n",
       "3         NaN             NaN    1ASI                 0              0   \n",
       "4         NaN             NaN  1ASIWS                 0              0   \n",
       "\n",
       "  IsFromVista                        TerminalID InternetOffice flight bookings  \n",
       "0           0  d41d8cd98f00b204e9800998ecf8427e            FRA             0.0  \n",
       "1           0  d41d8cd98f00b204e9800998ecf8427e            KIV             0.0  \n",
       "2           0  d41d8cd98f00b204e9800998ecf8427e            NYC             0.0  \n",
       "3           0  d41d8cd98f00b204e9800998ecf8427e            STO             0.0  \n",
       "4           0  d41d8cd98f00b204e9800998ecf8427e            OSL             0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_b['flight bookings'] = s_b['flight bookings'].fillna(0)\n",
    "s_b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el \"fillna(0)\" me da el valor en formato 'float', cambio el formato de la columna a 'integer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TxnCode</th>\n",
       "      <th>OfficeID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>NbSegments</th>\n",
       "      <th>Seg1Departure</th>\n",
       "      <th>...</th>\n",
       "      <th>Seg6Date</th>\n",
       "      <th>Seg6Carrier</th>\n",
       "      <th>Seg6BookingCode</th>\n",
       "      <th>From</th>\n",
       "      <th>IsPublishedForNeg</th>\n",
       "      <th>IsFromInternet</th>\n",
       "      <th>IsFromVista</th>\n",
       "      <th>TerminalID</th>\n",
       "      <th>InternetOffice</th>\n",
       "      <th>flight bookings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>20:25:57</td>\n",
       "      <td>MPT</td>\n",
       "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
       "      <td>DE</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TXL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>FRA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10:15:33</td>\n",
       "      <td>MPT</td>\n",
       "      <td>b0af35b31588dc4ab06d5cf2986e8e02</td>\n",
       "      <td>MD</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ATH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>KIV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>18:04:49</td>\n",
       "      <td>MPT</td>\n",
       "      <td>3561a60621de06ab1badc8ca55699ef3</td>\n",
       "      <td>US</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ICT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>NYC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:42:40</td>\n",
       "      <td>FXP</td>\n",
       "      <td>1864e5e8013d9414150e91d26b6a558b</td>\n",
       "      <td>SE</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>STO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:48:29</td>\n",
       "      <td>MPT</td>\n",
       "      <td>1ec336348f44207d2e0027dc3a68c118</td>\n",
       "      <td>NO</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OSL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>OSL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time TxnCode                          OfficeID Country  \\\n",
       "0  2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327      DE   \n",
       "1  2013-01-01  10:15:33     MPT  b0af35b31588dc4ab06d5cf2986e8e02      MD   \n",
       "2  2013-01-01  18:04:49     MPT  3561a60621de06ab1badc8ca55699ef3      US   \n",
       "3  2013-01-01  17:42:40     FXP  1864e5e8013d9414150e91d26b6a558b      SE   \n",
       "4  2013-01-01  17:48:29     MPT  1ec336348f44207d2e0027dc3a68c118      NO   \n",
       "\n",
       "  Origin Destination  RoundTrip  NbSegments Seg1Departure  ... Seg6Date  \\\n",
       "0    TXL         AUH        1.0         2.0           TXL  ...      NaN   \n",
       "1    ATH         MIL        0.0         1.0           ATH  ...      NaN   \n",
       "2    ICT         SFO        1.0         2.0           ICT  ...      NaN   \n",
       "3    RNB         ARN        0.0         1.0           RNB  ...      NaN   \n",
       "4    OSL         MAD        1.0         2.0           OSL  ...      NaN   \n",
       "\n",
       "  Seg6Carrier Seg6BookingCode    From IsPublishedForNeg IsFromInternet  \\\n",
       "0         NaN             NaN  1ASIWS                 0              0   \n",
       "1         NaN             NaN  1ASIWS                 0              0   \n",
       "2         NaN             NaN  1ASIWS                 0              0   \n",
       "3         NaN             NaN    1ASI                 0              0   \n",
       "4         NaN             NaN  1ASIWS                 0              0   \n",
       "\n",
       "  IsFromVista                        TerminalID InternetOffice flight bookings  \n",
       "0           0  d41d8cd98f00b204e9800998ecf8427e            FRA               0  \n",
       "1           0  d41d8cd98f00b204e9800998ecf8427e            KIV               0  \n",
       "2           0  d41d8cd98f00b204e9800998ecf8427e            NYC               0  \n",
       "3           0  d41d8cd98f00b204e9800998ecf8427e            STO               0  \n",
       "4           0  d41d8cd98f00b204e9800998ecf8427e            OSL               0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_b = s_b.astype({'flight bookings':int})\n",
    "s_b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Por útlimo, escribimos las búsquedas de vuelos realizas que han acabado en reservas, añadiéndole una columna con el valor '1' si la búsqueda se ha convertido en vuelo, y con el valor '0' si no ha sido así, a un fichero csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_b.to_csv('./searches_with_bookings.csv', sep = \"^\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
